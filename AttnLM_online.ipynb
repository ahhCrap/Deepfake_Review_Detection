{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AttnLM_online.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "URi3wv6idr03"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNA3qrMYRuAxb3XLrIB1dDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahhCrap/Deepfake_Review_Detection/blob/master/AttnLM_online.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogZO832XuFav",
        "colab_type": "text"
      },
      "source": [
        "# Attentive Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBpsztNquTBM",
        "colab_type": "text"
      },
      "source": [
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5gP6Rg2uDK2",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjzkQyFIr9u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn.modules.loss import NLLLoss\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBWWE3ict4mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.special as sps\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bEx6Eg9t83H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import pickle\n",
        "\n",
        "from tqdm import tqdm\n",
        "from random import random\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4SCXtxYtVsq",
        "colab_type": "code",
        "outputId": "54af1d86-d834-4d22-f1c8-a1a539966631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG0DJ5GOC3Vq",
        "colab_type": "text"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd2wUfiOC79i",
        "colab_type": "code",
        "outputId": "552f4046-06bf-432b-ecd9-5fb4d35d99c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = t.device(\"cuda:0\" if (t.cuda.is_available()) else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmFoBdFfm8m2",
        "colab_type": "code",
        "outputId": "5d45303a-f0c6-4dd9-a713-ac8d8acde20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EVwuYD-aLi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 1024\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "Q_DIM = K_DIM = V_DIM = 32\n",
        "HID_DIM = 1024\n",
        "EMB_DIM = 256\n",
        "\n",
        "MAX_LEN = 14\n",
        "MAX_SEQ = MAX_LEN + 1\n",
        "\n",
        "OPT = opt.Adam \n",
        "HEADS = 3\n",
        "N_LAY = 8\n",
        "LR = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcVFAEZpxHvt",
        "colab_type": "text"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmXMeJDx8LTN",
        "colab_type": "text"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AyqXJB-8OXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(filename):\n",
        "    infile = open(filename, 'rb')\n",
        "    file = pickle.load(infile)\n",
        "    infile.close()\n",
        "    return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjh-FduN8Ob5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save(file, filename):\n",
        "    outfile = open(filename, 'wb')\n",
        "    pickle.dump(file,outfile)\n",
        "    outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJzdn2nVnUSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def record_checkpoint(e, model, losses, version):\n",
        "    t.save({\n",
        "        'epoch': e,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': model.opt.state_dict(),\n",
        "        'losses': losses,\n",
        "        }, model_path + 'TRANS' + str(version) + '_checkpoint_' + str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ex36dswGpu4",
        "colab_type": "text"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VQ368iiksXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_online(file_path):\n",
        "    tokenized_sentences = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            tokenized_sentences += [word_tokenize(line.lower())]\n",
        "    return tokenized_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYaqEtpNIZfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ids_from_sent(sent):\n",
        "    return [vocab.word2index[tok] for tok in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVHPChUyIZim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tens_from_text(text):\n",
        "    return ([t.tensor([SOS] + ids_from_sent(s), device=device) for s in text], \n",
        "            [t.tensor(ids_from_sent(s) + [EOS], device=device) for s in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QU3PmWTapn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok2read = {'PAD': ' ', 'UNK': 'unk', 'SOS': '>>', 'EOS': '<<'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5q-5TV1Q2Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def raw2readable(sentence):\n",
        "    for i, w in enumerate(sentence):\n",
        "        if w in tok2read:\n",
        "            sentence[i] = tok2read[w]\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ukOOiGKd_7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok2adv = {'PAD': '', 'UNK': 'unk', 'SOS': '', 'EOS': ''}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofs4a0DAdgBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def raw2adversarial(sentence):\n",
        "    for i, w in enumerate(sentence):\n",
        "        if w in tok2adv:\n",
        "            sentence[i] = tok2adv[w]\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kA5efbYEeg6S",
        "colab": {}
      },
      "source": [
        "def compute_size(dataset):\n",
        "    dataset_size = 0\n",
        "    with open(dataset, 'r') as f:\n",
        "        for line in f:\n",
        "            dataset_size += 1\n",
        "    return dataset_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36RmL5YjC8lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_sentences(sentences):\n",
        "    assert isinstance(sentences[0], list), \"'sentences' is not list of list\"\n",
        "    return [['SOS']+sent+['EOS']+['PAD']*(MAX_SEQ-len(sent)-2) for sent in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YXd0-7J18lJ",
        "colab_type": "text"
      },
      "source": [
        "### Math"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7qo7a2EW_vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_angle(position, hid_idx, emb_dim):\n",
        "    return position / np.power(10000, 2 * (hid_idx // 2) / emb_dim)\n",
        "\n",
        "def get_posi_angle_vec(position, emb_dim):\n",
        "    return [cal_angle(position, hid_j, emb_dim) for hid_j in range(emb_dim)]\n",
        "\n",
        "def sinusoid_encoding_table(n_position, emb_dim=EMB_DIM):\n",
        "    sinusoid_table = np.array(\n",
        "        [get_posi_angle_vec(pos_i, emb_dim) for pos_i in range(n_position)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "\n",
        "    return t.tensor(sinusoid_table, dtype=t.float, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyzcadiAzr2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_mask(seq_q, seq_k):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    \n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k).to(device)  # batch_size x len_q x len_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBJ2zFetMpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_mask(batch_size, seq_len):\n",
        "    attn_shape = (batch_size, seq_len, seq_len)\n",
        "    subsequent_mask = t.triu(t.ones(attn_shape, dtype=t.bool, device=device), diagonal=1)\n",
        "    return subsequent_mask # subsequent_mask: [batch_size, seq, seq]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG_HRamSfdP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_like(tensor, t_like):\n",
        "    old_shape = tensor.shape\n",
        "    new_shape = t_like.shape\n",
        "    assert len(old_shape) == len(new_shape)\n",
        "    \n",
        "    diffs = []\n",
        "    for i in range(len(old_shape)):\n",
        "        diffs += [new_shape[i] - old_shape[i]]\n",
        "    pads = []\n",
        "    for d in diffs:\n",
        "        half = d//2\n",
        "        rest = d - half\n",
        "        pads.extend([half, rest])\n",
        "    \n",
        "    return F.pad(tensor, pads[::-1], mode='constant', value=PAD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNtJIfr2Rih-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXGpmqTP0zUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def truncated_permutation(n, max_n):\n",
        "    assert n < max_n\n",
        "\n",
        "    perm = set()\n",
        "    while len(perm) < n:\n",
        "        random_samples = np.random.randint(low=0, high=max_n-1, size=(n-len(perm)))\n",
        "        perm.update(random_samples.tolist())\n",
        "    return list(perm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-im3A_gVIaNr",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tAxmuRlJUB-",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFfpoLbyIZc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD = 0\n",
        "UNK = 1\n",
        "SOS = 2\n",
        "EOS = 3\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.word2count = {}\n",
        "        self.word2index = {'PAD': PAD, 'UNK': UNK, \"SOS\": SOS, \"EOS\": EOS}\n",
        "        self.index2word = {PAD: 'PAD', UNK: 'UNK', SOS: \"SOS\", EOS: \"EOS\"}\n",
        "        self.n_words = 4 \n",
        "        \n",
        "    def add_text(self, text):\n",
        "        for sent in tqdm(text): # assuming the text is a list of sentences\n",
        "            for tok in sent:\n",
        "                self.add_word(tok)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        try:\n",
        "            self.word2count[word] += 1\n",
        "        except KeyError:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "\n",
        "    def trim(self, n_tokens):\n",
        "        n_tokens -= 4 # Since we have 4 special characters\n",
        "        \n",
        "        words = list(self.word2count.keys())\n",
        "        counts = list(self.word2count.values())\n",
        "        counts, words = zip(*sorted(zip(counts, words))) # order the words by their usage\n",
        "        \n",
        "        # ============= Re-create 'word2index' and 'word2count' ================\n",
        "        temp_word2index = {'PAD': PAD, 'UNK': UNK, \"SOS\": SOS, \"EOS\": EOS}\n",
        "        temp_word2count = {PAD: 'PAD', UNK: 'UNK', SOS: \"SOS\", EOS: \"EOS\"}\n",
        "        temp_n_words = 4         \n",
        "        \n",
        "        for w in list(words)[-n_tokens:]:\n",
        "            temp_word2index[w] = temp_n_words\n",
        "            temp_word2count[w] = self.word2count[w]\n",
        "            temp_n_words += 1\n",
        "            \n",
        "        self.word2index = defaultdict(lambda: UNK, temp_word2index)\n",
        "        self.word2count = defaultdict(lambda: 0, temp_word2count)\n",
        "        self.n_words = temp_n_words\n",
        "            \n",
        "        # ====================== Re-create 'index2word' ========================\n",
        "        self.index2word = {}    \n",
        "        for w, i in self.word2index.items():\n",
        "            self.index2word[i] = w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e1Pr7skJXiz",
        "colab_type": "text"
      },
      "source": [
        "### Batcher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eH0a6SJAkBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creates the batches and pads sequences\n",
        "class Batcher:\n",
        "    def __init__(self, pad=PAD):\n",
        "        self.pad = pad\n",
        "\n",
        "    def get_batches(self, tensors, batch_size):\n",
        "        n = len(tensors)\n",
        "        drop = n % batch_size\n",
        "\n",
        "        dropped = tensors[-drop:] if drop != 0 else []\n",
        "\n",
        "        batches = []\n",
        "        for i in range(n // batch_size - 1):\n",
        "           batches.append(tensors[i * batch_size:(i + 1) * batch_size]) \n",
        "        \n",
        "        return batches, dropped\n",
        "    \n",
        "    def pad_batches(self, batches, batch_first=True):\n",
        "        swap = (1, 0) if batch_first else (0, 1)\n",
        "        return [pad_sequence(batch, padding_value=self.pad).permute(swap).to(device) for batch in batches]\n",
        "\n",
        "    def insta_batch(self, sents):\n",
        "        assert isinstance(sents[0], list), \"'sents' is not list of list\"\n",
        "\n",
        "        temp_sents = sents + [['dummy'] * MAX_LEN]\n",
        "        (inp_tens, tar_tens) = tens_from_text(temp_sents)\n",
        "        return (pad_sequence(inp_tens, padding_value=self.pad)[:, :-1].permute(1, 0).to(device),\n",
        "                pad_sequence(tar_tens, padding_value=self.pad)[:, :-1].permute(1, 0).to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esm2b4SJddMM",
        "colab_type": "text"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9WO19NJuIAJ",
        "colab_type": "text"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAa7zs4t2M4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MASK = float('-inf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3rQsZE7tKBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ScaledAttn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledAttn, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size, n_heads, seq_len, dim = Q.shape\n",
        "\n",
        "        scores = t.matmul(Q, K.transpose(-1, -2)) / np.sqrt(dim) # scores: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, MASK) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = t.matmul(attn, V)\n",
        "        return context, attn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7nCxUaom8s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified for self-attention only\n",
        "class MHA(nn.Module):\n",
        "    def __init__(self, emb_dim=EMB_DIM, dim=Q_DIM, n_heads=HEADS):\n",
        "        super(MHA, self).__init__()\n",
        "        \n",
        "        self.dim = dim # dimension of querys, keys and values\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_heads = n_heads\n",
        "        \n",
        "        self.W_Q = nn.Linear(emb_dim, n_heads * dim) \n",
        "        self.W_K = nn.Linear(emb_dim, n_heads * dim) \n",
        "        self.W_V = nn.Linear(emb_dim, n_heads * dim) \n",
        "        \n",
        "        self.projection = nn.Linear(n_heads * dim, emb_dim)\n",
        "        self.lay_norm = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x seq_len x dim], k: [batch_size x seq_len x dim], v: [batch_size x seq_len x dim]\n",
        "        residual = Q\n",
        "        batch_size, seq_len, emb_dim = Q.shape\n",
        "\n",
        "        # (B, S, E) -proj-> (B, S, H x D) -split-> (B, S, H, D) -trans-> (B, H, S, D)\n",
        "        q_s = self.W_Q(Q).view(batch_size, seq_len, self.n_heads, self.dim).transpose(1, 2)  # q_s: [batch_size x n_heads x seq_len x dim]\n",
        "        k_s = self.W_K(K).view(batch_size, seq_len, self.n_heads, self.dim).transpose(1, 2)  # k_s: [batch_size x n_heads x seq_len x dim]\n",
        "        v_s = self.W_V(V).view(batch_size, seq_len, self.n_heads, self.dim).transpose(1, 2)  # v_s: [batch_size x n_heads x seq_len x dim]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x seq_len x seq_len]\n",
        "\n",
        "        # context: [batch_size x n_heads x seq_len x dim], attn: [batch_size x n_heads x seq_len x seq_len]\n",
        "        context, attn = ScaledAttn()(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.n_heads * self.dim) # context: [batch_size x seq_len x n_heads * dim]\n",
        "        output = self.projection(context)\n",
        "        return self.lay_norm(output + residual), attn # output: [batch_size x seq_len x emb_dim]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WafxZzuNd75q",
        "colab_type": "text"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYtqzCJ1ucPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PWFF(nn.Module):\n",
        "    def __init__(self, emb_dim=EMB_DIM, hid_dim=HID_DIM):\n",
        "        super(PWFF, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(emb_dim, hid_dim, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(hid_dim, emb_dim, kernel_size=1)\n",
        "        self.lay_norm = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = self.conv1(inputs.transpose(1, 2))\n",
        "        output = t.relu(output)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.lay_norm(output + inputs)\n",
        "        return t.relu(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOHEL06VHhHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, emb_dim=EMB_DIM, hid_dim=HID_DIM, dim=Q_DIM, n_heads=HEADS):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.mha = MHA(emb_dim, dim, n_heads)\n",
        "        self.pwff = PWFF(emb_dim, hid_dim)\n",
        "\n",
        "    def forward(self, inputs, mask):\n",
        "        outputs, self_attn = self.mha(inputs, inputs, inputs, mask)\n",
        "        outputs = self.pwff(outputs)\n",
        "        return outputs, self_attn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmq2iBwxHhKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, emb_dim=EMB_DIM, hid_dim=HID_DIM, dim=Q_DIM, \n",
        "                 n_heads=HEADS, n_layers=N_LAY, vocab_size=VOCAB_SIZE):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.tgt_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_encoding_table(MAX_LEN+1+1, emb_dim), freeze=True)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(emb_dim, hid_dim, dim, n_heads)] * n_layers)\n",
        "\n",
        "    def forward(self, inputs): # dec_inputs : [batch_size x target_len]\n",
        "        batch_size, seq_len = inputs.shape\n",
        "\n",
        "        target_emb = self.tgt_emb(inputs) \n",
        "        target_emb += self.pos_emb(t.tensor(\n",
        "            [[seq_len]+[*range(1, seq_len)]] * batch_size, dtype=t.long).to(device))\n",
        "\n",
        "        padding = pad_mask(inputs, inputs)\n",
        "        subseq = seq_mask(batch_size, seq_len)\n",
        "        attn_mask = t.gt((padding + subseq), 0)\n",
        "\n",
        "        attns = []\n",
        "        for layer in self.layers:\n",
        "            dec_outputs, attn = layer(target_emb, attn_mask)\n",
        "            attns += [attn]\n",
        "        \n",
        "        return dec_outputs, attns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv6Nn7m4H6Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HeadedDecoder(nn.Module):\n",
        "    def __init__(self, emb_dim=EMB_DIM, hid_dim=HID_DIM, dim=Q_DIM, \n",
        "                 n_heads=HEADS, n_layers=N_LAY, vocab_size=VOCAB_SIZE):\n",
        "        super(HeadedDecoder, self).__init__()\n",
        "        \n",
        "        self.decoder = Decoder(emb_dim, hid_dim, dim, n_heads, n_layers, vocab_size)\n",
        "        self.projection = nn.Linear(emb_dim, vocab_size, bias=False)\n",
        "\n",
        "        self.opt = OPT(self.parameters(), LR)\n",
        "\n",
        "    def forward(self, dec_inputs):\n",
        "        dec_outputs, attns = self.decoder(dec_inputs)\n",
        "        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]\n",
        "        \n",
        "        probs = F.log_softmax(dec_logits, dim=-1)\n",
        "        return probs, attns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pft7NieSyN72",
        "colab_type": "text"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhrIG4zWyTNX",
        "colab_type": "text"
      },
      "source": [
        "### Iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awM6f_ZBzggw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_iter(model, input, target):\n",
        "    model.train()\n",
        "    model.opt.zero_grad()\n",
        "    \n",
        "    batch_size, seq_len = input.shape\n",
        "\n",
        "    probs, _ = model(input)\n",
        "\n",
        "    loss = NLLLoss(reduction='mean')(\n",
        "        probs.reshape(batch_size * seq_len, VOCAB_SIZE), \n",
        "        target.reshape(batch_size * seq_len))\n",
        "        \n",
        "    loss.backward()\n",
        "    model.opt.step()\n",
        "    return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTT8uiaSyWJX",
        "colab_type": "text"
      },
      "source": [
        "### Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QTqxScf_d49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_DOTS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjyFiSdr3Jtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch(file_path, model, batch_size=BATCH_SIZE):\n",
        "    d_size = compute_size(file_path)\n",
        "    with open(file_path, 'r') as f:\n",
        "        i = 1\n",
        "        batch = []\n",
        "        batch_losses = []\n",
        "        for line in f:\n",
        "            batch += [word_tokenize(json.loads(line)['review'].lower())]\n",
        "\n",
        "            if len(batch) == batch_size:\n",
        "                inp_batch, tar_batch = batcher.insta_batch(batch)\n",
        "                batch_losses += [train_iter(model, inp_batch, tar_batch)]\n",
        "                batch = []\n",
        "            # ----------------------- UPDATING PROGRESS ------------------------\n",
        "            if len(batch_losses) > i * ((d_size / batch_size) // N_DOTS):\n",
        "                print('.', sep='', end='') \n",
        "                i += 1\n",
        "            # ------------------------------------------------------------------ \n",
        "    print(' |', sep=' ', end=' ')\n",
        "    return sum(batch_losses) / len(batch_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNGLOd_PyWS1",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAi8nhFi_pAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(file_path, model, epochs, batch_size=BATCH_SIZE):\n",
        "    d_size = compute_size(file_path)\n",
        "    losses = []\n",
        "    for i in range(e, epochs+e):\n",
        "        print('Epoch:', '{:3d}'.format(i), '|', sep=' ', end=' ')\n",
        "        losses += [epoch(file_path, model, batch_size)]\n",
        "            \n",
        "        print('Loss:', '{:7.6f}'.format(losses[-1]), '|')\n",
        "    return losses, epochs+e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPUw531mirkD",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrLw0TvCXonM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tensors2sentences(tensors, vocab, batched=True, at=2):\n",
        "    if not batched: tensors = tensors.unsqueeze(0)\n",
        "    sentences = []\n",
        "    for i in range(tensors.size(0)):\n",
        "        sentences += [[vocab.index2word[n.item()] for n in tensors[i, :]]]\n",
        "        if i > at: break\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqAu5xNYH6JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_decoder(model, start_symbol=SOS):\n",
        "    model.eval()\n",
        "\n",
        "    dec_input = t.zeros(1, MAX_LEN + 1, dtype=t.long).to(device) # PAD = 0\n",
        "    next_symbol = start_symbol\n",
        "\n",
        "    for i in range(MAX_SEQ):\n",
        "        dec_input[0][i] = next_symbol\n",
        "\n",
        "        dec_outputs, attn = model.decoder(dec_input)\n",
        "        dec_outputs = model.projection(dec_outputs)\n",
        "\n",
        "        probs, ids = dec_outputs.squeeze().max(dim=-1, keepdim=False)\n",
        "        next_symbol = ids.data[i].item()\n",
        "    \n",
        "    return ids, attn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLmw3_Spfl62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def topk_decoder(model, k=10, start_symbol=SOS):\n",
        "    model.eval()\n",
        "\n",
        "    dec_input = t.zeros(1, MAX_LEN + 1, dtype=t.long).to(device) # PAD = 0\n",
        "    next_symbol = start_symbol\n",
        "    dec_input[0][0] = next_symbol\n",
        "\n",
        "    for i in range(MAX_SEQ):\n",
        "        new_pool = int(k * (1 - i/MAX_SEQ) + 1)\n",
        "\n",
        "        probs, attn = model(dec_input)\n",
        "        top_vals, top_ids = t.topk(probs.squeeze(), k=new_pool, dim=-1)\n",
        "        top_ids = top_ids[i, :]\n",
        "\n",
        "        pick = int(random() * new_pool)\n",
        "        next_symbol = top_ids.data[pick].item()\n",
        "        dec_input[0][i] = next_symbol\n",
        "\n",
        "    return dec_input.squeeze(), attn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzf1wossmyHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def temperature_decoder(model, temp=5, start_symbol=SOS):\n",
        "    model.eval()\n",
        "\n",
        "    dec_input = t.zeros(1, MAX_LEN + 1, dtype=t.long).to(device) # PAD = 0\n",
        "    next_symbol = start_symbol\n",
        "    dec_input[0][0] = next_symbol\n",
        "\n",
        "    new_temp = temp\n",
        "    for i in range(MAX_SEQ):\n",
        "        probs, attn = model(dec_input)\n",
        "        temperature_probs = F.softmax(probs / new_temp, dim=-1)[0, i, :].cpu().data.numpy()\n",
        "        next_symbol = np.random.choice(len(temperature_probs), size=(1), p=temperature_probs)\n",
        "        dec_input[0][i] = t.tensor(next_symbol, dtype=t.long)\n",
        "        \n",
        "        # Exponental decay\n",
        "        #new_temp /= 2\n",
        "        # Linear decay\n",
        "        new_temp = temp * (1 - (i+2)/MAX_SEQ) + 1e-6\n",
        "\n",
        "    return dec_input.squeeze(), attn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVB61e5_PO42",
        "colab_type": "text"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URi3wv6idr03",
        "colab_type": "text"
      },
      "source": [
        "## Data Structuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vij-eMsVbZ7D",
        "colab": {}
      },
      "source": [
        "dir_path = '/content/drive/My Drive/POLIMI/Thesis/Data/Datasets/Food/'\n",
        "model_path = '/content/drive/My Drive/POLIMI/Thesis/Data/Models/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Kyu2VS52Is",
        "colab_type": "code",
        "outputId": "35c13d30-e3ef-420e-eac2-aab1d29d2700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_name = 'test.jsonl'\n",
        "file_path = dir_path + train_name\n",
        "file_path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/POLIMI/Thesis/Data/Datasets/Food/test.jsonl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "34487cd3-b2e1-4a86-cfbf-071d2cadb2fa",
        "id": "cOwdoBtBbZ7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = Vocab()\n",
        "vocab.add_text(tokenize_online(file_path))\n",
        "vocab.trim(VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 95439/95439 [00:00<00:00, 124851.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xR2c3FwRbZ7O",
        "colab": {}
      },
      "source": [
        "batcher = Batcher()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhJ5FYdPdobp",
        "colab_type": "code",
        "outputId": "8e09b7c3-c669-4450-8f77-75b629cdfad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compute_size(file_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKBtJhp_pdGU",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQt-BPnUqi6h",
        "colab_type": "code",
        "outputId": "2329fac2-cc51-4742-ea97-71f91c25084d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = HeadedDecoder(EMB_DIM, HID_DIM, Q_DIM, HEADS, N_LAY, VOCAB_SIZE).to(device)\n",
        "count_params(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1149728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftScep1DVkDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESTART = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFaAfDj5MjO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if RESTART:\n",
        "    e = 0\n",
        "    losses = []\n",
        "else:\n",
        "    VERSION = 2\n",
        "    e = 16\n",
        "\n",
        "    checkpoint = t.load(model_path + 'TRANS' +  str(VERSION) + '_checkpoint_' + str(e), map_location=t.device(device))\n",
        "    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    e = checkpoint['epoch']\n",
        "\n",
        "    losses = checkpoint['losses']\n",
        "    model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6DvjcNrMyq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VERSION = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-zTVIvBUXOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 16\n",
        "TIMES = 1\n",
        "START = 0\n",
        "MID = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytvfDr8EUabr",
        "colab_type": "code",
        "outputId": "f08c6ba1-db2d-43d7-925c-21438b71d5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "for j in range(START, START + TIMES):\n",
        "\n",
        "    # -------------------------- PARAMETERS SETTING ----------------------------\n",
        "    lr = LR\n",
        "    epcs =  EPOCHS \n",
        "    batch_size = BATCH_SIZE * (2**j)\n",
        "    if MID is True: \n",
        "        model.opt = OPT(model.parameters(), lr, betas=[0.9, 0.999])\n",
        "    print('Batch Size:', batch_size, '|', 'Learning Rate:', lr)\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    loss, e = train(file_path, model, epcs, batch_size)\n",
        "    losses += loss\n",
        "\n",
        "    record_checkpoint(e, model, losses, VERSION)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Size: 64 | Learning Rate: 0.0001\n",
            "Epoch:   0 | .......... | Loss: 2.241120 |\n",
            "Epoch:   1 | .......... | Loss: 1.834055 |\n",
            "Epoch:   2 | .......... | Loss: 1.760567 |\n",
            "Epoch:   3 | .......... | Loss: 1.719383 |\n",
            "Epoch:   4 | .......... | Loss: 1.690709 |\n",
            "Epoch:   5 | .......... | Loss: 1.668445 |\n",
            "Epoch:   6 | .......... | Loss: 1.650018 |\n",
            "Epoch:   7 | .......... | Loss: 1.634321 |\n",
            "Epoch:   8 | .......... | Loss: 1.620717 |\n",
            "Epoch:   9 | .......... | Loss: 1.608665 |\n",
            "Epoch:  10 | .......... | Loss: 1.597857 |\n",
            "Epoch:  11 | .......... | Loss: 1.587986 |\n",
            "Epoch:  12 | .......... | Loss: 1.578884 |\n",
            "Epoch:  13 | .......... | Loss: 1.570377 |\n",
            "Epoch:  14 | .......... | Loss: 1.562415 |\n",
            "Epoch:  15 | .......... | Loss: 1.554859 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSjNWaApU4AN",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFGfqABUgrm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TAKE = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZGkWfdmgn6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if TAKE:\n",
        "    EPOCH_COMPARE = 16\n",
        "    VERSION_COMPARE = 33\n",
        "\n",
        "    checkpoint_compare = t.load(\n",
        "        model_path + str(VERSION_COMPARE) + '_checkpoint_' + str(EPOCH_COMPARE), \n",
        "        map_location=t.device(device))\n",
        "    \n",
        "    nll_losses_compare = checkpoint_compare['nll_losses']\n",
        "    # kld_losses_compare = checkpoint_compare['kld_losses']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqDdppe_-pe9",
        "colab_type": "code",
        "outputId": "1ecd2536-1d55-409d-dea4-7604f191d161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(losses, 'bX-' ,label='Transformer')\n",
        "plt.plot(nll_losses_compare, 'ro-' ,label='Variational AE')\n",
        "plt.title('Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFNCAYAAABfWL0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlcMG5vXTAAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4C0mrALQqdW",
        "colab_type": "code",
        "outputId": "a6b0928a-3ac6-4521-ae73-6cc4057d92ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dec_input, attn = greedy_decoder(model, SOS)\n",
        "'SOS '+' '.join(vocab.index2word[inp.item()] for inp in dec_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SOS great product EOS EOS EOS EOS EOS EOS EOS EOS EOS . EOS EOS EOS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5mVLub1ZSGZ",
        "colab_type": "code",
        "outputId": "6877c4de-8a6c-4f07-f692-db0abc143bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dec_input, attn = topk_decoder(model, k=10, start_symbol=SOS)\n",
        "'SOS '+' '.join(vocab.index2word[inp.item()] for inp in dec_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SOS good UNK as PAD timely PAD UNK , PAD PAD PAD PAD UNK EOS PAD'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDRcPefMeRmm",
        "colab_type": "code",
        "outputId": "60f9aafe-4acc-46b3-95bf-91cdd45ded8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dec_input, attn = temperature_decoder(model, temp=4, start_symbol=SOS)\n",
        "'SOS '+' '.join(vocab.index2word[inp.item()] for inp in dec_input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SOS it looking PAD fast PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd7Uz02jyo-J",
        "colab_type": "text"
      },
      "source": [
        "## Adversarial Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H8v-rjD2IJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ADV_SIZE = 1024\n",
        "SAFETY = 50\n",
        "TEMP = 4\n",
        "K = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh9L1Aq4vFIC",
        "colab_type": "code",
        "outputId": "c1b672a7-55ec-4444-d4c6-aa4d4593b73f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "adv_dataset = set()\n",
        "for i in tqdm(range(ADV_SIZE + SAFETY)):\n",
        "    out, _ = topk_decoder(model, k=K, start_symbol=SOS)\n",
        "    sentence = ['SOS'] + [vocab.index2word[inp.item()] for inp in out]\n",
        "    adv_dataset.add(' '.join(raw2adversarial(sentence))[1:])\n",
        "\n",
        "adv_dataset = sorted(list(adv_dataset))[:ADV_SIZE]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1074/1074 [02:50<00:00,  6.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htkMxcYi4AdQ",
        "colab_type": "code",
        "outputId": "aca1ec3d-414a-4101-93a5-acf7d72b1097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "GENERATE_IT = True\n",
        "if GENERATE_IT:\n",
        "    adv_path = dir_path + 'adversarial_k' + str(K) + '.jsonl'\n",
        "    with open(adv_path, 'w') as f:\n",
        "        i = 0\n",
        "        for r in tqdm(adv_dataset):\n",
        "            json.dump({'id': i, 'review': r}, f)\n",
        "            f.write('\\n')\n",
        "            i += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 58762.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBI7qdVD2Q7c",
        "colab_type": "code",
        "outputId": "c820b51f-b5db-4a59-d295-907261060417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "second_adv_dataset = set()\n",
        "for i in tqdm(range(ADV_SIZE + SAFETY)):\n",
        "    out, _ = temperature_decoder(model, temp=TEMP, start_symbol=SOS)\n",
        "    sentence = ['SOS'] + [vocab.index2word[inp.item()] for inp in out]\n",
        "    second_adv_dataset.add(' '.join(raw2adversarial(sentence))[1:])\n",
        "\n",
        "second_adv_dataset = sorted(list(second_adv_dataset))[:ADV_SIZE]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1074/1074 [02:53<00:00,  6.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJA_qIU01u3p",
        "colab_type": "code",
        "outputId": "f7a8d97c-453d-43e6-d365-a9f41fa5bc76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "GENERATE_IT = True\n",
        "if GENERATE_IT:\n",
        "    adv_path = dir_path + 'adversarial_temp' + str(TEMP) + '.jsonl'\n",
        "    with open(adv_path, 'w') as f:\n",
        "        i = 0\n",
        "        for r in tqdm(second_adv_dataset):\n",
        "            json.dump({'id': i, 'review': r}, f)\n",
        "            f.write('\\n')\n",
        "            i += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:00<00:00, 59647.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2yL0zW646gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}